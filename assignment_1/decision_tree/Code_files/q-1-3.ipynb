{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "### we have to build a decision tree from scratch using various calclulations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 (10 points)\n",
    "#### Contrast the effectiveness of Misclassification rate, Gini, En-tropy as impurity measures in terms of precision, recall and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imporitng Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import random\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "eps = numpy.finfo(float).eps\n",
    "from copy import deepcopy\n",
    "maxdepth = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading data from CSV and it's analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>7</td>\n",
       "      <td>286</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.93</td>\n",
       "      <td>4</td>\n",
       "      <td>249</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>accounting</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.71</td>\n",
       "      <td>4</td>\n",
       "      <td>151</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>5</td>\n",
       "      <td>163</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.10             0.90               7                   286   \n",
       "1                0.89             0.93               4                   249   \n",
       "2                0.38             0.50               2                   132   \n",
       "3                0.95             0.71               4                   151   \n",
       "4                0.84             0.84               5                   163   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years       sales  \\\n",
       "0                   4              0     1                      0       sales   \n",
       "1                   3              0     0                      0       sales   \n",
       "2                   3              0     1                      0  accounting   \n",
       "3                   4              0     0                      0       sales   \n",
       "4                   3              0     0                      0   technical   \n",
       "\n",
       "   salary  \n",
       "0     low  \n",
       "1     low  \n",
       "2     low  \n",
       "3  medium  \n",
       "4     low  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('input_data/train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11238 entries, 0 to 11237\n",
      "Data columns (total 10 columns):\n",
      "satisfaction_level       11238 non-null float64\n",
      "last_evaluation          11238 non-null float64\n",
      "number_project           11238 non-null int64\n",
      "average_montly_hours     11238 non-null int64\n",
      "time_spend_company       11238 non-null int64\n",
      "Work_accident            11238 non-null int64\n",
      "left                     11238 non-null int64\n",
      "promotion_last_5years    11238 non-null int64\n",
      "sales                    11238 non-null object\n",
      "salary                   11238 non-null object\n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 878.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So, there is no missing values in the dataset and hence no preprocessing of filling missing values is to be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "satisfaction_level       0\n",
       "last_evaluation          0\n",
       "number_project           0\n",
       "average_montly_hours     0\n",
       "time_spend_company       0\n",
       "Work_accident            0\n",
       "left                     0\n",
       "promotion_last_5years    0\n",
       "sales                    0\n",
       "salary                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the count of both the outcomes\n",
    "- As the probelm is of binary classification , we first checked the skewness of the data towards an outcome.\n",
    "- We can see that the zeroes count is much more than the ones count hence the tree will be biased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8563</td>\n",
       "      <td>8563</td>\n",
       "      <td>8563</td>\n",
       "      <td>8563</td>\n",
       "      <td>8563</td>\n",
       "      <td>8563</td>\n",
       "      <td>8563</td>\n",
       "      <td>8563</td>\n",
       "      <td>8563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2675</td>\n",
       "      <td>2675</td>\n",
       "      <td>2675</td>\n",
       "      <td>2675</td>\n",
       "      <td>2675</td>\n",
       "      <td>2675</td>\n",
       "      <td>2675</td>\n",
       "      <td>2675</td>\n",
       "      <td>2675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      satisfaction_level  last_evaluation  number_project  \\\n",
       "left                                                        \n",
       "0                   8563             8563            8563   \n",
       "1                   2675             2675            2675   \n",
       "\n",
       "      average_montly_hours  time_spend_company  Work_accident  \\\n",
       "left                                                            \n",
       "0                     8563                8563           8563   \n",
       "1                     2675                2675           2675   \n",
       "\n",
       "      promotion_last_5years  sales  salary  \n",
       "left                                        \n",
       "0                      8563   8563    8563  \n",
       "1                      2675   2675    2675  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('left').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling and spliting the data\n",
    "- As mentioned in the assignment, we will first shuffle the data and then split it into two splits\n",
    "- 80% Training Set\n",
    "- 20% Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.sample(frac = 0.8, random_state = 200)\n",
    "test_data = data.drop(train_data.index)\n",
    "#train_data, test_data = numpy.split(data, [int(0.8 * len(data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iscontinous(data,attr):\n",
    "    if attr == 'left':\n",
    "        return True\n",
    "    if attr in list(data._get_numeric_data()):\n",
    "        if len(data[attr].unique()) <= 2 :\n",
    "            return False\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = list(data)\n",
    "attr.remove('left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Work_accident', 'promotion_last_5years', 'sales', 'salary']\n",
      "['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours', 'time_spend_company']\n"
     ]
    }
   ],
   "source": [
    "categorical = [ x for x in attr if iscontinous(data,x) == False]\n",
    "continous = [x for x in attr if iscontinous(data,x) == True]\n",
    "print(categorical)\n",
    "print(continous)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function will return unique values of a particular column given as parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_values(data,col):\n",
    "    return list(data[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['low', 'medium', 'high']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_unique_values(data,'salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### This function will list the column headers for any dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attributes(data):\n",
    "    return list(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy ( Updated in this part ) :\n",
    "#### We added a parameter suggesting which type of entropy calculation we want -> typeoffunction\n",
    ">- Entropy is the term of imputiry of the system, that is how much variation is present in the outcome.\n",
    ">- The following function will take a dataframe and output label as an input and will calculate the entropy on the basis of frequency of output labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(data, labelcol,typeoffunction):\n",
    "    \n",
    "    dic = dict(data[labelcol].value_counts())\n",
    "    if typeoffunction == 'entropy':\n",
    "        \n",
    "        entropy = 0.0\n",
    "        for label in dic.keys():\n",
    "            entropy = entropy + (-(((1.0)*dic[label])/(len(data) + eps) * numpy.log2(((1.0)*dic[label])/(len(data) + eps )) ) ) \n",
    "            #print(entropy)\n",
    "        return entropy\n",
    "    if typeoffunction == 'gini':\n",
    "        q = 0.0\n",
    "        if 1 in dic.keys():\n",
    "            q = q + 2.0*(((1.0)*dic[1])/(len(data) + eps) * ( 1 - ((((1.0)*dic[1])/(len(data) + eps)))))\n",
    "        return q\n",
    "    if typeoffunction == 'misclassification':\n",
    "        q = 0.0\n",
    "        if 1 in dic.keys():\n",
    "            q = min((((1.0)*dic[1])/(len(data) + eps) , ( 1 - ((((1.0)*dic[1])/(len(data) + eps))))))\n",
    "        return q\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24215795328142381"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(train_data,'left','misclassification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Gain\n",
    ">- information gain is reduction in the entropy if we use a feature ( attribute ) as an decision boundary.\n",
    ">- It calculates wieghted entropy for the unique values of the attribute and then subtracts it from the current entropy of the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infogain(data, attr,labelcol,functiontype):\n",
    "    uniq = get_unique_values(data,attr)\n",
    "    wt_entropy = 0.0\n",
    "    for vals in uniq:\n",
    "        selected_data = data.loc[data[attr] == vals]\n",
    "        wieght = (1.0*len(selected_data))/(len(data) + eps )\n",
    "        wt_entropy += wieght*entropy(selected_data,labelcol,functiontype)\n",
    "        #print(wt_entropy)\n",
    "    return entropy(data, labelcol,functiontype) - wt_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information gain for numerical attribute:\n",
    "> We sort the unique values and sort them and now considetring all points as an splitting point and selecting a point which gives maximum gain the storing the numerical split in the node and then spliting the data for >= spliting point and < spliting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infogainfornumerical(data,attr,labelcol,functiontype):\n",
    "   \n",
    "    #df.sort_values(attr)\n",
    "    #print(df)\n",
    "    lista = list(data[attr].unique())\n",
    "    listb = sorted(lista)\n",
    "    midpoints = []\n",
    "    for x in range(1,len(listb)):\n",
    "        midpoints.append((listb[x-1] + listb[x])/2.0)\n",
    "        \n",
    "    maxgain = 0.0\n",
    "    splitingpoint = -1\n",
    "    dictof = {} \n",
    "    for x in midpoints:\n",
    "        #print(x)\n",
    "        data2 = data[data[attr] > x]\n",
    "        data3 = data[data[attr] <= x]\n",
    "        leftentropy = ((1.0*len(data2)) / len(data))*entropy(data2,labelcol,functiontype)\n",
    "        rightentropy = ((1.0*len(data3)) / len(data))*entropy(data3,labelcol,functiontype)\n",
    "        wt_entropy = leftentropy + rightentropy\n",
    "        infogain = entropy(data, labelcol,functiontype) - wt_entropy\n",
    "        if infogain > maxgain:\n",
    "            maxgain = infogain\n",
    "            splitingpoint = x\n",
    "    return maxgain,splitingpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0092627199526159609"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infogain(data,'salary','left','gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcoldata(data,attr,value):\n",
    "    return data.loc[data[attr] == value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum Gain\n",
    "- Out of a list of attributes, we have to select that which attribute will be selected as a best decision boundary and for that we calculate inforamtion gain of eact feature and select the one whcih has max gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_gain(data, remaining_attrs , labelcol,functiontype):\n",
    "    maxgain = 0.0\n",
    "    splitattr = \"\"\n",
    "    splitingpointmain = -1\n",
    "    global continous\n",
    "    for attr in remaining_attrs:\n",
    "        if attr in continous:\n",
    "            gain,splitingpoint = infogainfornumerical(data,attr,labelcol,functiontype)\n",
    "        else:\n",
    "            gain  = infogain(data,attr,labelcol,functiontype)\n",
    "            splitingpoint = -1\n",
    "        #print (attr,gain)\n",
    "        if  gain >= maxgain:\n",
    "            maxgain = gain\n",
    "            splitattr = attr\n",
    "            splitingpointmain = splitingpoint \n",
    "    if splitattr == \"\" :\n",
    "        #print(\"NOT IN THIS\")\n",
    "        return 0,\"Negative\",-1\n",
    "    return maxgain,splitattr,splitingpointmain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.060400444938820907, 'satisfaction_level', 0.46499999999999997)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr = list(data)\n",
    "attr.remove('left')\n",
    "max_gain(train_data,attr,'left','misclassification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printtree(root):\n",
    "    if(len(root.children.keys()) == 0):\n",
    "        #print(\"descion \" + str(root.descion)) \n",
    "        global countdes\n",
    "        countdes += 1\n",
    "        return\n",
    "    #print(root.attr)\n",
    "    for x in list(root.children.keys())[::-1]:\n",
    "        #print(x)\n",
    "        printtree(root.children[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node of decision tree.\n",
    ">- I have build id3 type structure of the tree that is each node will have n-ary children depending upon the number of unique values of the feature selected on that node.\n",
    ">- Each node has a dictionary which will have key ( branch ) as its unique values and for each key there will be a node.\n",
    ">- I have taken following attribute for the node\n",
    ">>- attribute name selceted on that node\n",
    ">>- decision on that node\n",
    ">>- Dictionary of children\n",
    ">>- depth\n",
    ">>- positive count ( number of 1s )\n",
    ">>- negative count ( numbers of 0s )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class node:\n",
    "    attr = \"\"\n",
    "    decision = -1\n",
    "    children = {}\n",
    "    depth = 0\n",
    "    positive_count = 0\n",
    "    negative_count = 0\n",
    "    isnumeric = False\n",
    "    splitingpoint  = -1\n",
    "    \n",
    "    def __init__(self,attr,decision,children,depth,positive_count,negative_count,isnumeric, splitingpoint):\n",
    "        self.attr = attr\n",
    "        self.decision = decision\n",
    "        self.children = children\n",
    "        self.depth = depth\n",
    "        self.positive_count = positive_count\n",
    "        self.negative_count = negative_count\n",
    "        self.isnumeric = isnumeric\n",
    "        self.splitingpoint = splitingpoint\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building tree recursively\n",
    ">- We first select the attribue with maximum gain , make it the root node and recurse the funciton for all its unique value.\n",
    ">- We stop at two conditions \n",
    ">>1. If there are rows only of onr type of output\n",
    ">>2. If all the attributes are used in the path.\n",
    ">>> In that case we make decision on the probablity of outcome till that node.\n",
    ">>3. If there are numerical attributes, we will binary split the data while finding the spliting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:54: SyntaxWarning: name 'maxdepth' is assigned to before global declaration\n",
      "<>:54: SyntaxWarning: name 'maxdepth' is assigned to before global declaration\n",
      "<>:54: SyntaxWarning: name 'maxdepth' is assigned to before global declaration\n",
      "<ipython-input-75-043051b284a8>:54: SyntaxWarning: name 'maxdepth' is assigned to before global declaration\n",
      "  global maxdepth\n"
     ]
    }
   ],
   "source": [
    "def building_tree(data ,attrs , depth , functiontype ):\n",
    "    #print(attrs)\n",
    "\n",
    "    posnegcount = dict(data['left'].value_counts())\n",
    "    poscount = 0\n",
    "    negcount = 0\n",
    "    \n",
    "    if 1 in posnegcount.keys():\n",
    "        poscount = posnegcount[1]\n",
    "    if 0 in posnegcount.keys():\n",
    "        negcount = posnegcount[0]\n",
    "    gain , best_attr , splitingpoint = max_gain(data,attrs,'left',functiontype)\n",
    "    \n",
    "    \n",
    "    if(gain == 0):\n",
    "        ans = 1\n",
    "        if negcount > poscount:\n",
    "            ans = 0\n",
    "        return node('left',ans,{},depth,poscount,negcount,False,-1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if len(attrs) <= 0 or poscount == 0 or negcount == 0:\n",
    "        ans = 1\n",
    "        if negcount > poscount:\n",
    "            ans = 0\n",
    "        return node('left',ans,{},depth,poscount,negcount,False,-1)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        #print(best_attr)\n",
    "        if splitingpoint != -1:\n",
    "            root = node(best_attr,\"\",{},depth,poscount,negcount,True,splitingpoint)\n",
    "            \n",
    "            newattr = deepcopy(attrs)\n",
    "            #newattr.remove(best_attr)\n",
    "            for childs in range(0,2):\n",
    "                key = 0\n",
    "                if childs == 0:\n",
    "                    data2 = data[ data[best_attr] > splitingpoint ]\n",
    "                    key = 1\n",
    "                else:\n",
    "                    data2 = data[ data[best_attr] <= splitingpoint ]\n",
    "                global maxdepth\n",
    "                maxdepth = max(depth,maxdepth)\n",
    "                root.children[key] = building_tree(data2,newattr,depth+1,functiontype)\n",
    "        else:\n",
    "            uniqvals = get_unique_values(data,best_attr)\n",
    "            root = node( best_attr , \"\" , {} , depth , poscount , negcount,False,-1)\n",
    "            for val in uniqvals:\n",
    "                data2 = getcoldata(data,best_attr,val)\n",
    "                newattr = deepcopy(attrs)\n",
    "                newattr.remove(best_attr)\n",
    "                global maxdepth\n",
    "                maxdepth = max(depth,maxdepth)\n",
    "                root.children[val] = building_tree(data2, newattr , depth+1,functiontype)\n",
    "        \n",
    "        return root\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funtion to handle missing values in test data\n",
    ">- I implemented what was taught in the tutorial, what i did is that if a missing value is found in test row, it makes a recursive call on each of it's children and all the children returns the majority of ones or zeroes they have traversing throughout the leaf node.\n",
    "\n",
    ">- if there are other features that are present in that row, the recursion will follow that part only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_missing_node(root,row):\n",
    "    onecount = 0\n",
    "    zerocount = 0\n",
    "    #print(root.attr)\n",
    "    if len(root.children.keys()) == 0 or root.attr == 'left':\n",
    "        if(root.positive_count <= root.negative_count):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        for x in root.children.keys():\n",
    "            try:\n",
    "#             if math.isnan(row[x]) == False:\n",
    "                root = root.children[row[x]]\n",
    "                z = predict_missing_node(root,row)\n",
    "                if z == 0:\n",
    "                    zerocount += 1\n",
    "                else:\n",
    "                    onecount += 1\n",
    "                break\n",
    "            except:\n",
    "                z = predict_missing_node(root.children[x],row)\n",
    "                if z == 0:\n",
    "                    zerocount += 1\n",
    "                else:\n",
    "                    onecount += 1\n",
    "        if(onecount > zerocount):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Function:\n",
    "> We traverse from root node for each row till the decison node, and then predict the same.\n",
    ">#### In case, if a path is not in the trained tree and it is in test set (that is we cant parse downwars stuck on that node, we give decsion on the basis of probablity of that node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree,rows):\n",
    "    while(len(tree.children.keys()) != 0):\n",
    "        #print(str(rows)+\"row\")\n",
    "        #print(rows['salary'])\n",
    "        x = rows[tree.attr]\n",
    "        #print(tree.attr,x,tree.isnumeric)\n",
    "        if tree.isnumeric == True:\n",
    "            if ( x > tree.splitingpoint):\n",
    "                tree = tree.children[1]\n",
    "            else:\n",
    "                tree = tree.children[0]\n",
    "        else:\n",
    "            try:\n",
    "                tree = tree.children[x]\n",
    "            except:\n",
    "                #print(\"here\")\n",
    "                tree.decision = predict_missing_node(tree,rows)\n",
    "               # if(tree.positive_count < tree.negative_count):\n",
    "\n",
    "                break\n",
    "#                         else:\n",
    "#                             tree.decision = 1\n",
    "#                         break\n",
    "    return tree.decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict2(valid_data, tree):\n",
    "    rightcount = 0\n",
    "    wrongcount = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    origin = deepcopy(tree)\n",
    "    for index,rows in valid_data.iterrows():\n",
    "        tree = origin\n",
    "        decision = predict(tree,rows)\n",
    "        \n",
    "        if(decision == rows['left']):\n",
    "            rightcount+=1\n",
    "            if(rows['left'] == 0):\n",
    "                true_negative += 1\n",
    "            if(rows['left'] == 1):\n",
    "                true_positive += 1\n",
    "        else:\n",
    "            if(rows['left'] == 0):\n",
    "                false_positive += 1\n",
    "            if(rows['left'] == 1):\n",
    "                false_negative += 1\n",
    "            wrongcount+=1\n",
    "    print(\"True negative : \" , true_negative)\n",
    "    print(\"True positive : \",true_positive)\n",
    "    print(\"False Positive :\",false_positive)\n",
    "    print(\"False negative :\",false_negative)\n",
    "    print(\"Total right predicted: \", rightcount)\n",
    "    print(\"Total wrong predicted: \", wrongcount)\n",
    "    print(\"Accuracy: \" , rightcount/(rightcount+wrongcount))\n",
    "    print(\"Precision: \",true_positive/(true_positive+ false_positive))\n",
    "    print(\"Recall: \",true_positive/(true_positive  + false_negative))\n",
    "    print(\"F1 Score: \",(2.0)/((1/(true_positive/(true_positive + false_positive))) + (1/(true_positive/(true_positive+false_negative)))))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini Index Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root: satisfaction_level\n",
      "depth:  18\n"
     ]
    }
   ],
   "source": [
    "maxdepth = 0\n",
    "tree = building_tree(train_data,attr,0,'gini')\n",
    "print(\"Root:\",tree.attr)\n",
    "print(\"depth: \",maxdepth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of leaf nodes: 437\n"
     ]
    }
   ],
   "source": [
    "countdes = 0\n",
    "printtree(tree)\n",
    "print(\"number of leaf nodes:\",countdes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True negative :  1717\n",
      "True positive :  484\n",
      "False Positive : 33\n",
      "False negative : 14\n",
      "Total right predicted:  2201\n",
      "Total wrong predicted:  47\n",
      "Accuracy:  0.9790925266903915\n",
      "Precision:  0.9361702127659575\n",
      "Recall:  0.9718875502008032\n",
      "F1 Score:  0.9536945812807881\n"
     ]
    }
   ],
   "source": [
    "predict2(test_data,tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missclassification Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root: satisfaction_level\n",
      "depth:  16\n"
     ]
    }
   ],
   "source": [
    "maxdepth = 0\n",
    "tree = building_tree(train_data,attr,0,'misclassification')\n",
    "print(\"Root:\",tree.attr)\n",
    "print(\"depth: \",maxdepth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of leaf nodes: 212\n"
     ]
    }
   ],
   "source": [
    "countdes = 0\n",
    "printtree(tree)\n",
    "print(\"number of leaf nodes:\",countdes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True negative :  1740\n",
      "True positive :  469\n",
      "False Positive : 10\n",
      "False negative : 29\n",
      "Total right predicted:  2209\n",
      "Total wrong predicted:  39\n",
      "Accuracy:  0.9826512455516014\n",
      "Precision:  0.9791231732776617\n",
      "Recall:  0.9417670682730924\n",
      "F1 Score:  0.9600818833162742\n"
     ]
    }
   ],
   "source": [
    "predict2(test_data,tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root: satisfaction_level\n",
      "depth:  15\n"
     ]
    }
   ],
   "source": [
    "maxdepth = 0\n",
    "tree = building_tree(train_data,attr,0,'entropy')\n",
    "print(\"Root:\",tree.attr)\n",
    "print(\"depth: \",maxdepth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of leaf nodes: 375\n"
     ]
    }
   ],
   "source": [
    "countdes = 0\n",
    "printtree(tree)\n",
    "print(\"number of leaf nodes:\",countdes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True negative :  1713\n",
      "True positive :  482\n",
      "False Positive : 37\n",
      "False negative : 16\n",
      "Total right predicted:  2195\n",
      "Total wrong predicted:  53\n",
      "Accuracy:  0.9764234875444839\n",
      "Precision:  0.928709055876686\n",
      "Recall:  0.9678714859437751\n",
      "F1 Score:  0.9478859390363817\n"
     ]
    }
   ],
   "source": [
    "predict2(test_data,tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
